---
layout: post
title: Rails Caching + Cronjob = Crazy Delicious!
---
This is some placeholder text copied from my current blog.

I recently dumped my Wordpress blog in favor of building my own blog in Rails. As you can see, you can count the number of features I need from my blogging software on one hand. I didn't have an opportunity to work in Rails 2.1 yet and I needed a small project to experience what deploying a real, live Rails site is like. So far it's been a blast. Passenger has been a dream to work with and Dreamhost makes it as simple as checking a checkbox to enable it. All I had to do was write a simple rsync command to sync my local and live directories.

So far this entire site is a textbook application. I haven't hit any roadblocks that Google couldn't help me blast through. That is, until I tried to tackle consuming a Twitter feed.

My problem wasn't in retrieving and parsing the Twitter XML feed. I'm using Net::HTTP to retrieve the XML and parsing it with a REXML::Document. It's by-the-book Ruby code. The trouble I was having was with caching. A simple caching scenario works like this: some hipster sitting in Starbucks leaching WiFi and sipping a grande skinny mocha latte with whip wants to bone up on the awesomeness that is JavaScript. He types developmentastic.com into Safari (obviously a Mac user, duh) and my brilliant website springs into action doing a few milliseconds of intense, painful work. It decides since nothing on this page ever changes because I'm a slacker and never post anything, it might as well save the output so when another echo-conscious latte-lover accidentally clicks on the wrong Google result and ends up here, it can just hand them the same result.